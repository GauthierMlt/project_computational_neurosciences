{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import datetime\n",
    "import re\n",
    "from os import listdir\n",
    "import sys\n",
    "import copy as cp\n",
    "sys.path.insert(0, '../model_tf2')\n",
    "import parameters\n",
    "import plotting_functions as pf\n",
    "import data_utils as du\n",
    "import model_utils as mu\n",
    "import behaviour_analyses as ba\n",
    "import environments as ef\n",
    "import cell_analyses as ca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "WARNING:tensorflow:From c:\\Users\\gaumu\\anaconda3\\envs\\dlmi\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\gaumu\\anaconda3\\envs\\dlmi\\Lib\\site-packages\\keras\\src\\saving\\legacy\\save.py:538: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
      "\n",
      "Not running forward pass: C:/Users/gaumu/Desktop/TEM_linux/Summaries/2024-03-11/run0/save/iter_1494 already exists\n",
      "But no files exist!\n",
      "yes C:/Users/gaumu/Desktop/TEM_linux/Summaries/2024-03-11/run0/save\n",
      "Loading model time point 1494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gaumu\\anaconda3\\envs\\dlmi\\Lib\\site-packages\\keras\\src\\initializers\\initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: '/C:Users\\\\gaumu\\\\Desktop\\\\TEM_linux\\\\Summaries\\\\2024-03-11\\\\run0\\\\save/params.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo trained model weights found for \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m date \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, run \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m run \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Load data, generated either during training or in a forward pass through a trained model\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m data, para, list_of_files, save_path, env_dict \u001b[38;5;241m=\u001b[39m \u001b[43mpf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                                             \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                                             \u001b[49m\u001b[43msmoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_series_smoothing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                                             \u001b[49m\u001b[43mn_envs_save\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Assign parameters\u001b[39;00m\n\u001b[0;32m     57\u001b[0m params, widths, n_states \u001b[38;5;241m=\u001b[39m para\n",
      "File \u001b[1;32mc:\\Users\\gaumu\\Desktop\\TEM_linux\\model_tf2\\../model_tf2\\plotting_functions.py:390\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(save_dirs, run, date, recent, index, smoothing, n_envs_save)\u001b[0m\n\u001b[0;32m    387\u001b[0m params_path \u001b[38;5;241m=\u001b[39m params_path_append \u001b[38;5;241m+\u001b[39m path\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;241m*\u001b[39mparams_path[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(params_path[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m save_path\n\u001b[0;32m    389\u001b[0m \u001b[38;5;66;03m# Load run parameters\u001b[39;00m\n\u001b[1;32m--> 390\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_numpy_gz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/params.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    391\u001b[0m params \u001b[38;5;241m=\u001b[39m DotDict(params)\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_envs_save \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\gaumu\\Desktop\\TEM_linux\\model_tf2\\../model_tf2\\parameters.py:380\u001b[0m, in \u001b[0;36mload_numpy_gz\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_numpy_gz\u001b[39m(file_name):\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m    382\u001b[0m         f \u001b[38;5;241m=\u001b[39m gzip\u001b[38;5;241m.\u001b[39mGzipFile(file_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.gz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gaumu\\anaconda3\\envs\\dlmi\\Lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: '/C:Users\\\\gaumu\\\\Desktop\\\\TEM_linux\\\\Summaries\\\\2024-03-11\\\\run0\\\\save/params.npy'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ADD YOUR DIRECTORIES HERE\n",
    "\n",
    "path = 'C:/Users/gaumu/Desktop/TEM_linux/Summaries/'\n",
    "save_dirs = [path]\n",
    "\n",
    "# Choose which training run data to load\n",
    "date = '2024-03-11'\n",
    "run = '0'\n",
    "index = None  # '1000', None\n",
    "\n",
    "# grid cells: date = [saved], '2021-10-03', run = '4', index=1000\n",
    "# grid cells: date = [saved], '2021-09-05', run = '0' (hex grids, square world, relu) \n",
    "# - also use for place-grid metric figure\n",
    "# grid cells: date = [saved], '2021-08-30', run = '3' (hex grids, square world, relu)\n",
    "# grid cells: date = [saved], '2021-09-29', run = '7' (hex world)\n",
    "# place cells: date = [saved], '2021-09-29', run = '0'\n",
    "\n",
    "# Try to find the most recent trained model data to run a forward pass\n",
    "recent = -1\n",
    "time_series_smoothing = 1\n",
    "try:\n",
    "    # Find model path and iteration index\n",
    "    save_dir, index = pf.get_model_path(run, date, save_dirs, recent, index=index)\n",
    "    # Run forward path for retrieved model, if folder doesn't exist yet\n",
    "    model = ba.save_trained_outputs(date, run, int(index), base_path=save_dir, \\\n",
    "                                    force_overwrite=False, n_envs_save=16)\n",
    "except FileNotFoundError:\n",
    "    print('No trained model weights found for ' + date + ', run ' + run + '.')\n",
    "        \n",
    "# Load data, generated either during training or in a forward pass through a trained model\n",
    "data, para, list_of_files, save_path, env_dict = pf.get_data(save_dirs, run, date, recent, \\\n",
    "                                                             index=index, \\\n",
    "                                                             smoothing=time_series_smoothing, \\\n",
    "                                                             n_envs_save=16)\n",
    "# Assign parameters\n",
    "params, widths, n_states = para\n",
    "\n",
    "# Specify plotting parameters. Some fields will be added after loading data & parameters\n",
    "plot_specs = pf.__plot_specs\n",
    "\n",
    "# Set plot_spec fields that depend on parameters after loading\n",
    "plot_specs.index = index\n",
    "plot_specs.world_type = params.world_type\n",
    "plot_specs.directory = save_path.split('save/')[0]\n",
    "\n",
    "import seaborn\n",
    "#sns.set(font_scale = 2)\n",
    "seaborn.set_style(style='white')\n",
    "seaborn.set_style({'axes.spines.bottom': False,'axes.spines.left': False,'axes.spines.right': \\\n",
    "                   False,'axes.spines.top': False})\n",
    "\n",
    "masks, g_lim = pf.sort_data(data.g, widths, plot_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "masks = [(np.sum(g,1) != 0).tolist() for g in data.g]\n",
    "trainalbe_variables = model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for env in range(min(params.n_envs_save, len(data.acc_to))):\n",
    "    num_correct = np.sum(data.acc_to[env] * data.positions[env])\n",
    "    proportion = num_correct / sum(data.positions[env])\n",
    "    _n_states = len(data.positions[env] > 0.01)\n",
    "    approx_num = proportion * _n_states\n",
    "    print(env, '   Approx proportion : ', np.round(proportion, decimals=3), \\\n",
    "          '   Approx num : ' + str(int(np.round(approx_num, decimals=4)[0])) \\\n",
    "          + ' of ' + str(_n_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env0 = 2\n",
    "env1 = 3\n",
    "envs = [env0, env1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env_ = env_dict.curric_env.envs[0]\n",
    "env_.world()\n",
    "# plot different transitions in different colours\n",
    "for i in range(env_.adj.shape[0]):\n",
    "    for j in range(env_.adj.shape[1]):\n",
    "        if env_.adj[i,j] != 0:\n",
    "            ri, rt = env_.relation(i,j)\n",
    "            env_.adj[i,j] = ri + 1\n",
    "plt.imshow(env_.adj)\n",
    "w,v = np.linalg.eig(env_.adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "try:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    for i, env in enumerate([env0, env1]):\n",
    "        adj_ = pf.remove_zero_adj(data.adj[env])\n",
    "        plt.subplot(1,2,i + 1)\n",
    "        g = nx.from_numpy_matrix(adj_)\n",
    "        pos_nodes = nx.spring_layout(g, iterations=500)\n",
    "        nx.draw(g, pos=pos_nodes, node_size=50, with_labels=True)\n",
    "    plt.show()\n",
    "except TypeError:\n",
    "    plt.close('all')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## AGENT COVERAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_specs.cmap = 'copper'\n",
    "try:\n",
    "    s = plot_specs[parameters.old2new(params.world_type)].marker_size\n",
    "    marker = plot_specs[parameters.old2new(params.world_type)].marker_shape\n",
    "except:\n",
    "    print('exceptiom')\n",
    "    s, marker = 10, 'H'\n",
    "figsize = (16,8)\n",
    "s_scale = 20\n",
    "plt.figure(figsize=figsize) \n",
    "for i, env in enumerate([env0, env1]):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    pos, bins = np.histogram(data.pos_timeseries[env], bins=np.arange(n_states[env]+1))\n",
    "    xs, ys, cell_prepared = env_dict.curric_env.envs[env].get_node_positions(\n",
    "        cells=pos, _plot_specs=plot_specs)\n",
    "    plt.scatter(xs, ys, c=cell_prepared, s=s*s_scale, marker=marker, vmin=0, \\\n",
    "                cmap=plot_specs.cmap)\n",
    "    plt.xlim(xmin=min(xs)-1, xmax=max(xs)+1)\n",
    "    plt.ylim(ymin=min(ys)-1, ymax=max(ys)+1)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.colorbar()\n",
    "    print(min(cell_prepared), max(cell_prepared))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# where the agent didnt go much shown in black\n",
    "figsize= (8 * len(envs), 8)\n",
    "plt.figure(figsize=figsize)\n",
    "s_scale = 20\n",
    "for i, env in enumerate([env0, env1]):\n",
    "    pos, bins = np.histogram(data.pos_timeseries[env], bins=np.arange(n_states[env]+1))\n",
    "    a = pos > 5\n",
    "    plt.subplot(1,2,i+1)\n",
    "    xs, ys, cell_prepared = env_dict.curric_env.envs[env].get_node_positions(\n",
    "        cells=a.astype(float), _plot_specs=plot_specs)\n",
    "    plt.scatter(xs, ys, c=cell_prepared, s=s*s_scale, marker=marker, vmin=0, cmap=plot_specs.cmap)\n",
    "    plt.xlim(xmin=min(xs)-1, xmax=max(xs)+1)\n",
    "    plt.ylim(ymin=min(ys)-1, ymax=max(ys)+1)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.colorbar()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ACCURACY MAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figsize= (8 * len(envs), 16)\n",
    "s_scale = 10\n",
    "plt.figure(figsize=figsize)        \n",
    "for i, env in enumerate([env0, env1]):\n",
    "    plt.subplot(3,2,2*i+1)    \n",
    "    xs, ys, cell_prepared = env_dict.curric_env.envs[env].get_node_positions(\n",
    "        cells=data.acc_to[env], _plot_specs=plot_specs)\n",
    "    plt.scatter(xs, ys, c=cell_prepared, cmap=plot_specs.cmap, s=s*s_scale, \\\n",
    "                marker=marker, vmin=0, vmax=1)\n",
    "    plt.xlim(xmin=min(xs)-1, xmax=max(xs)+1)\n",
    "    plt.ylim(ymin=min(ys)-1, ymax=max(ys)+1)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.colorbar()\n",
    "    plt.title('accuracy to : env ' + str(env))\n",
    "    \n",
    "    plt.subplot(3,2,2*i+2)\n",
    "    xs, ys, cell_prepared = env_dict.curric_env.envs[env].get_node_positions(\n",
    "        cells=data.acc_from[env], _plot_specs=plot_specs)\n",
    "    plt.scatter(xs, ys, c=cell_prepared, cmap=plot_specs.cmap, s=s*s_scale, \\\n",
    "                marker=marker, vmin=0, vmax=1)\n",
    "    plt.xlim(xmin=min(xs)-1, xmax=max(xs)+1)\n",
    "    plt.ylim(ymin=min(ys)-1, ymax=max(ys)+1)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.colorbar()\n",
    "    plt.title('accuracy from : env ' + str(env))\n",
    "# average across envs - should do this properly with position counts\n",
    "env = 0\n",
    "# find other envs of same size\n",
    "accs_to = [acc_to for i, acc_to in enumerate(data.acc_to) if n_states[i] == n_states[env]]\n",
    "accs_from = [acc_from for i, acc_from in enumerate(data.acc_from) if n_states[i] == n_states[env]]\n",
    "\n",
    "plt.subplot(3,2,5)\n",
    "xs, ys, cell_prepared = env_dict.curric_env.envs[env].get_node_positions(\n",
    "    cells=np.mean(accs_to, axis=0), _plot_specs=plot_specs)\n",
    "plt.scatter(xs, ys, c=cell_prepared, cmap=plot_specs.cmap, s=s*s_scale, \\\n",
    "            marker=marker, vmin=0, vmax=1)\n",
    "plt.xlim(xmin=min(xs)-1, xmax=max(xs)+1)\n",
    "plt.ylim(ymin=min(ys)-1, ymax=max(ys)+1)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.colorbar()\n",
    "plt.title('accuracy to - averaged over all envs')\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.subplot(3,2,6)\n",
    "xs, ys, cell_prepared = env_dict.curric_env.envs[env].get_node_positions(\n",
    "    cells=np.mean(accs_from, axis=0), _plot_specs=plot_specs)\n",
    "plt.scatter(xs, ys, c=cell_prepared, cmap=plot_specs.cmap, s=s*s_scale, \\\n",
    "            marker=marker, vmin=0, vmax=1)\n",
    "plt.xlim(xmin=min(xs)-1, xmax=max(xs)+1)\n",
    "plt.ylim(ymin=min(ys)-1, ymax=max(ys)+1)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.colorbar()\n",
    "plt.title('accuracy from - averaged over all envs')\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Inner-prods and softmax probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#variables = model_utils.DotDict(np.load('/Users/jameswhittington/Dropbox/gen_struct_know/model_tf2' + '/asdsad.npy', allow_pickle=True).item())\n",
    "lookback=1\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.subplot(1,2,1)\n",
    "_ = plt.hist(np.stack(data.final_variables.mem_dist.inner_prods)[-lookback:,...].flatten() \\\n",
    "             [np.stack(data.final_variables.mem_dist.inner_prods)[-lookback:,...].flatten() \\\n",
    "              > -100], bins=50)\n",
    "plt.subplot(1,2,2)\n",
    "_ = plt.hist(np.stack(data.final_variables.mem_dist.probabilities)[-lookback:,...].flatten(), \\\n",
    "             bins=np.linspace(0.01, 1, 50))\n",
    "plt.savefig(plot_specs.directory + 'scal_prods_probs' + '_' + plot_specs.index + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "g_reps = data.g_timeseries[0][:,:400].T\n",
    "reps = model.g2p(g_reps).numpy()\n",
    "n_k = reps.shape[-1]\n",
    "scal_prods = np.matmul(reps, reps.T)\n",
    "scal_prods = mu.threshold(scal_prods, n_k*params.kernel_thresh_min, \\\n",
    "                          n_k*params.kernel_thresh_max, thresh_slope=0.001).numpy()\n",
    "scal_prods = scal_prods / np.sqrt(reps.shape[-1])\n",
    "_ = plt.hist(scal_prods.flatten(), bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ENTORHINAL CELLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_specs.split_freqs = False\n",
    "plot_specs.n_cells_freq = params.g_size\n",
    "plot_specs.cmap = 'jet'\n",
    "plot_specs.node_plot = True\n",
    "plot_specs.max_min = True\n",
    "plot_specs.smoothing = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(g_lim[0], label='min')\n",
    "plt.plot(g_lim[1], label='max')\n",
    "plt.legend()\n",
    "plt.savefig(plot_specs.directory + 'g_max_min' + '_' + plot_specs.index + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pf.square_plot(data.g, env0, params, plot_specs, name='g0_'+index, lims=g_lim, mask=masks[env0], \\\n",
    "               env_class=env_dict.curric_env.envs[env0], fig_dir=plot_specs.directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pf.square_plot(data.g, env1, params, plot_specs, name='g1_'+index, lims=g_lim, mask=masks[env1], \\\n",
    "               env_class=env_dict.curric_env.envs[env1], fig_dir=plot_specs.directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ENTORHINAL AUTOCORRELATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#plot_specs.graph_auto = True\n",
    "#pf.square_autocorr_plot(data.g, env0, params, plot_specs, name='g0_auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#pf.square_autocorr_plot(data.g, env1, params, plot_specs, name='g1_auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 'Place' Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gs=[]\n",
    "for i, g_b in enumerate(data.g):\n",
    "    gs_b = []\n",
    "    for j in range(params.max_states):\n",
    "        try:\n",
    "            g = g_b[j]\n",
    "        except IndexError:\n",
    "            g = np.zeros(params.g_size)\n",
    "            \n",
    "        gs_b.append(g)\n",
    "    gs.append(np.stack(gs_b, axis=0))\n",
    "gs = np.stack(gs, axis=1)\n",
    "\n",
    "# repeat gs to get correct batch size:\n",
    "reps = np.ceil(params.batch_size/gs.shape[1]).astype(int)\n",
    "gs = np.tile(gs, [1,reps,1])\n",
    "gs = gs[:,:params.batch_size,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# place cells\n",
    "\n",
    "ps = []\n",
    "g2ps = []\n",
    "for g in gs:\n",
    "    train_i = 1000000\n",
    "    scalings = parameters.get_scaling_parameters(train_i, params)\n",
    "    inputs_test_tf = mu.inputs_2_tf(env_dict.inputs, env_dict.hebb, scalings)\n",
    "    memories_dict, variable_dict = model.init_input(inputs_test_tf)\n",
    "    mem_step = model.mem_step(memories_dict, 0)\n",
    "\n",
    "    retrieved_g2x, g_mem_input, hidden_g2x = model.gen_p(g, mem_step)\n",
    "    \n",
    "    g2ps.append(model.g2p(g).numpy())\n",
    "    \n",
    "    ps.append(hidden_g2x['stored']['prob'].numpy())\n",
    "ps = np.stack(ps, axis=1)\n",
    "g2ps = np.stack(g2ps, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(np.min(g2ps, axis=(0,2)), label='min')\n",
    "plt.plot(np.max(g2ps, axis=(0,2)), label='max')\n",
    "plt.legend()\n",
    "plt.savefig(plot_specs.directory + 'g2p_max_min' + '_' + plot_specs.index + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(g_lim[0], label='min')\n",
    "plt.plot(g_lim[1], label='max')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "g2ps_ = []\n",
    "for b, g2p in enumerate(g2ps):\n",
    "    g2ps_.append(g2p[:env_dict.curric_env.envs[b].n_states,:])\n",
    "\n",
    "pf.square_plot(g2ps_, env0, params, plot_specs, name='g2p0_'+index, lims=None, mask=masks[env0], \\\n",
    "               env_class=env_dict.curric_env.envs[env0], fig_dir=plot_specs.directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ps_ = []\n",
    "for b, p in enumerate(ps):\n",
    "    ps_.append(p[:env_dict.curric_env.envs[b].n_states,:])\n",
    "pf.square_plot(ps_, env0, params, plot_specs, name='p0_'+index, lims=None, mask=masks[env0], \\\n",
    "               env_class=env_dict.curric_env.envs[env0], fig_dir=plot_specs.directory)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Grid score analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Grid score and scale\n",
    "\"\"\"\n",
    "fit_ellipse = True\n",
    "ring = True\n",
    "\n",
    "module_analysis_gc = []\n",
    "\n",
    "env=env1\n",
    "\n",
    "rows = np.ceil(np.sqrt(data.g[env].shape[1])).astype(int)\n",
    "fix, axes = plt.subplots(rows, rows, figsize=(15, 15))\n",
    "\n",
    "scores_all = []\n",
    "for i, cell in enumerate(data.g[env].T): \n",
    "    if i%10 ==0:\n",
    "        print(str(i), end=' ')\n",
    "    rate_map = pf.cell_plot_prepare(cell, widths[env], masks[env], plot_specs)           \n",
    "    auto = pf.autocorr2d_no_nans(rate_map) \n",
    "    auto = np.nan_to_num(auto, nan=0)\n",
    "    score, scale, theta = ca.grid_score_scale_analysis(auto, fit_ellipse=fit_ellipse, ring=ring)\n",
    "    scores_all.append(score)\n",
    "    norm_firing = np.mean(cell**2)\n",
    "    \n",
    "    #if score > -1.0:\n",
    "    module_analysis_gc.append([i, score, scale, theta, norm_firing])\n",
    "    \n",
    "    ax = axes[int(i/rows)][i%rows]\n",
    "    ax.imshow(auto, cmap='jet')\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(str(score)[:4])  \n",
    "\n",
    "plt.savefig(plot_specs.directory + 'auto_scores' + '_' + plot_specs.index + \".pdf\", dpi=300)\n",
    "plt.show()\n",
    "    \n",
    "scores, scales, thetas, norm_firings = [], [], [], []\n",
    "for x in module_analysis_gc:\n",
    "    scores.append(x[1])\n",
    "    scales.append(x[2])\n",
    "    thetas.append(x[3])\n",
    "    norm_firings.append(x[4])\n",
    "        \n",
    "scores = np.asarray(scores)\n",
    "scales = np.asarray(scales)\n",
    "thetas = np.asarray(thetas)\n",
    "norm_firings = np.asarray(norm_firings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot score distribution\n",
    "import seaborn as sns\n",
    "fig, axes = plt.subplots(1, 1, figsize=(8, 8))\n",
    "sns.histplot(ax=axes, data=scores, bins=20, stat='density')\n",
    "sns.kdeplot(ax=axes, data=scores, bw_method='scott', bw_adjust=0.8, c='k')\n",
    "axes.set_title('grid score distribution', fontsize=20)\n",
    "plt.savefig(plot_specs.directory + 'grid_score_distribution' + '_' + plot_specs.index + \".pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "sns.histplot(ax=axes[0], data=scores, bins=20, stat='density')\n",
    "sns.kdeplot(ax=axes[0], data=scores, bw_method='scott', bw_adjust=0.8, c='k')\n",
    "axes[0].set_title('scores')\n",
    "\n",
    "sns.histplot(ax=axes[1], data=scales, bins=20, stat='density')\n",
    "sns.kdeplot(ax=axes[1], data=scales, bw_method='scott', bw_adjust=0.4, c='k')\n",
    "axes[1].set_title('scales')\n",
    "\n",
    "sns.histplot(ax=axes[2], data=thetas, bins=20, stat='density')\n",
    "sns.kdeplot(ax=axes[2], data=thetas, bw_method='scott', bw_adjust=0.4, c='k')\n",
    "axes[2].set_title('thetas')\n",
    "\n",
    "sns.histplot(ax=axes[3], data=norm_firings, bins=20, stat='density')\n",
    "sns.kdeplot(ax=axes[3], data=norm_firings, bw_method='scott', bw_adjust=0.4, c='k')\n",
    "axes[3].set_title('norm firing')\n",
    "\n",
    "plt.savefig(plot_specs.directory + 'scores_scales_thetas' + '_' + plot_specs.index + \".pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot cells with gird score over threshold\n",
    "module_analysis_gc_array = np.asarray(module_analysis_gc)\n",
    "thresh = 0.0\n",
    "norm_thresh = 0.01\n",
    "over_thresh = module_analysis_gc_array[module_analysis_gc_array[:,1] > thresh, :]\n",
    "over_thresh = over_thresh[over_thresh[:,4] > norm_thresh]\n",
    "# sort accorinding to grid score\n",
    "over_thresh = over_thresh[(-over_thresh[:, 1]).argsort()]\n",
    "\n",
    "n_cells = over_thresh.shape[0]\n",
    "rows = np.ceil(np.sqrt(n_cells)).astype(int)\n",
    "fix, axes = plt.subplots(rows, rows, figsize=(25, 25))\n",
    "for i, cell_num in enumerate(over_thresh[:,0]):\n",
    "    cell_num = int(cell_num)\n",
    "    cell = data.g[env][:,cell_num]\n",
    "    rate_map = pf.cell_plot_prepare(cell, widths[env], masks[env], plot_specs)\n",
    "    ax = axes[int(i/rows)][i%rows]\n",
    "    ax.imshow(rate_map, cmap='jet')\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(str(over_thresh[i,1])[:4])  \n",
    "    \n",
    "plt.savefig(plot_specs.directory + 'ordered_by_scores' + '_' + plot_specs.index + \".pdf\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Place cell analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Place score\n",
    "\"\"\"\n",
    "\n",
    "env=env1\n",
    "\n",
    "rows = np.ceil(np.sqrt(ps_[env].shape[1])).astype(int)\n",
    "fix, axes = plt.subplots(rows, rows, figsize=(15, 15))\n",
    "\n",
    "scores_all = []\n",
    "for i, cell in enumerate(ps_[env].T): \n",
    "    if i%10 ==0:\n",
    "        print(str(i), end=' ')\n",
    "    rate_map = pf.cell_plot_prepare(cell, widths[env], masks[env], plot_specs)    \n",
    "    \n",
    "    score = ca.place_cell_metric(rate_map)\n",
    "    scores_all.append(score)\n",
    "    \n",
    "    ax = axes[int(i/rows)][i%rows]\n",
    "    ax.imshow(rate_map, cmap='jet')\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(str(score)[:4])  \n",
    "\n",
    "plt.savefig(plot_specs.directory + 'place_scores' + '_' + plot_specs.index + \".pdf\", dpi=300)\n",
    "plt.show()\n",
    "    \n",
    "scores = np.asarray(scores_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cell_num_ordered = np.arange(len(scores))[(-scores).argsort()]\n",
    "scores_ordered = scores[(-scores).argsort()]\n",
    "cell_num_ordered = cell_num_ordered[np.isfinite(scores_ordered)]\n",
    "scores_ordered = scores_ordered[np.isfinite(scores_ordered)]\n",
    "\n",
    "n_cells = len(scores_ordered)\n",
    "rows = np.ceil(np.sqrt(n_cells)).astype(int)\n",
    "fix, axes = plt.subplots(rows, rows, figsize=(25, 25))\n",
    "\n",
    "for i, (cell_num, score) in enumerate(zip(cell_num_ordered, scores_ordered)):\n",
    "    cell_num = int(cell_num)\n",
    "    cell = ps_[env][:,cell_num]\n",
    "    rate_map = pf.cell_plot_prepare(cell, widths[env], masks[env], plot_specs)\n",
    "    ax = axes[int(i/rows)][i%rows]\n",
    "    ax.imshow(rate_map, cmap='jet')\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(str(score)[:4])  \n",
    "    \n",
    "plt.savefig(plot_specs.directory + 'place_ordered_by_scores' + '_' + plot_specs.index + \".pdf\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compare grid to place\n",
    "\"\"\"\n",
    "\n",
    "env=env1\n",
    "\n",
    "scores_all = []\n",
    "for i, cell in enumerate(ps_[env].T): \n",
    "    if i%10 ==0:\n",
    "        print(str(i), end=' ')\n",
    "    rate_map = pf.cell_plot_prepare(cell, widths[env], masks[env], plot_specs)    \n",
    "    \n",
    "    score = ca.place_cell_metric(rate_map)\n",
    "    scores_all.append(score)\n",
    "    \n",
    "scores_pc = np.asarray(scores_all)\n",
    "\n",
    "scores_all = []\n",
    "for i, cell in enumerate(data.g[env].T): \n",
    "    if i%10 ==0:\n",
    "        print(str(i), end=' ')\n",
    "    rate_map = pf.cell_plot_prepare(cell, widths[env], masks[env], plot_specs)    \n",
    "    norm_firing = np.mean(cell**2)\n",
    "    \n",
    "    if norm_firing > norm_thresh and i in np.asarray(module_analysis_gc)[:,0]:\n",
    "        a = np.argmax(np.asarray(module_analysis_gc)[:,0] == i)\n",
    "        if np.asarray(module_analysis_gc)[a, 1] > 1.0:\n",
    "            score = ca.place_cell_metric(rate_map)\n",
    "            scores_all.append(score)\n",
    "    \n",
    "scores_gc = np.asarray(scores_all)\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(8, 8))\n",
    "sns.histplot(ax=axes, data=scores_pc, bins=20, stat='density', label='place cells',color='g')\n",
    "sns.kdeplot(ax=axes, data=scores_pc, bw_method='scott', bw_adjust=0.4, c='k')\n",
    "\n",
    "sns.histplot(ax=axes, data=scores_gc, bins=20, stat='density', label='grid cells')\n",
    "sns.kdeplot(ax=axes, data=scores_gc, bw_method='scott', bw_adjust=0.4, c='k')\n",
    "\n",
    "axes.set_title('place metric distribution', fontsize=20)\n",
    "axes.legend(fontsize=20)\n",
    "\n",
    "#plt.hist(scores_pc, bins=20, range=[0,1], density=True, label='place cells')\n",
    "#plt.hist(scores_gc, bins=20, range=[0,1], density=True, label='grid cells')\n",
    "plt.savefig(plot_specs.directory + 'place_grid_scores' + '_' + plot_specs.index + \".pdf\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Place score\n",
    "\"\"\"\n",
    "\n",
    "env=env1\n",
    "\n",
    "rows = np.ceil(np.sqrt(ps_[env].shape[1])).astype(int)\n",
    "fix, axes = plt.subplots(rows, rows, figsize=(15, 15))\n",
    "\n",
    "scores_all = []\n",
    "for i, cell in enumerate(ps_[env].T): \n",
    "    if i%10 ==0:\n",
    "        print(str(i), end=' ')\n",
    "    rate_map = pf.cell_plot_prepare(cell, widths[env], masks[env], plot_specs)    \n",
    "    \n",
    "    score = ca.place_cell_metric(rate_map)\n",
    "    scores_all.append(score)\n",
    "    \n",
    "    ax = axes[int(i/rows)][i%rows]\n",
    "    ax.imshow(rate_map, cmap='jet')\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(str(score)[:4])  \n",
    "\n",
    "plt.savefig(plot_specs.directory + 'place_scores' + '_' + plot_specs.index + \".pdf\", dpi=300)\n",
    "plt.show()\n",
    "    \n",
    "scores = np.asarray(scores_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Grid score and scale on place cells!\n",
    "\"\"\"\n",
    "fit_ellipse = True\n",
    "ring = True\n",
    "\n",
    "module_analysis_pc = []\n",
    "\n",
    "env=env1\n",
    "\n",
    "rows = np.ceil(np.sqrt(ps_[env].shape[1])).astype(int)\n",
    "fix, axes = plt.subplots(rows, rows, figsize=(15, 15))\n",
    "\n",
    "scores_all = []\n",
    "for i, cell in enumerate(ps_[env].T): \n",
    "    if i%10 ==0:\n",
    "        print(str(i), end=' ')\n",
    "    rate_map = pf.cell_plot_prepare(cell, widths[env], masks[env], plot_specs)           \n",
    "    auto = pf.autocorr2d_no_nans(rate_map) \n",
    "    auto = np.nan_to_num(auto, nan=0)\n",
    "    score, scale, theta = ca.grid_score_scale_analysis(auto, fit_ellipse=fit_ellipse, ring=ring)\n",
    "    scores_all.append(score)\n",
    "    norm_firing = np.mean(cell**2)\n",
    "    \n",
    "    if score > 0.0:\n",
    "        module_analysis_pc.append([i, score, scale, theta, norm_firing])\n",
    "    \n",
    "    ax = axes[int(i/rows)][i%rows]\n",
    "    ax.imshow(auto, cmap='jet')\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(str(score)[:4])  \n",
    "\n",
    "plt.savefig(plot_specs.directory + 'auto_scores' + '_' + plot_specs.index + \".pdf\", dpi=300)\n",
    "plt.show()\n",
    "    \n",
    "scores, scales, thetas, norm_firings = [], [], [], []\n",
    "for x in module_analysis_pc:\n",
    "    scores.append(x[1])\n",
    "    scales.append(x[2])\n",
    "    thetas.append(x[3])\n",
    "    norm_firings.append(x[4])\n",
    "        \n",
    "scores = np.asarray(scores)\n",
    "scales = np.asarray(scales)\n",
    "thetas = np.asarray(thetas)\n",
    "norm_firings = np.asarray(norm_firings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "sns.histplot(ax=axes[0], data=scores, bins=20, stat='density')\n",
    "sns.kdeplot(ax=axes[0], data=scores, bw_method='scott', bw_adjust=0.4, c='k')\n",
    "axes[0].set_title('scores')\n",
    "\n",
    "sns.histplot(ax=axes[1], data=scales, bins=20, stat='density')\n",
    "sns.kdeplot(ax=axes[1], data=scales, bw_method='scott', bw_adjust=0.4, c='k')\n",
    "axes[1].set_title('scales')\n",
    "\n",
    "sns.histplot(ax=axes[2], data=thetas, bins=20, stat='density')\n",
    "sns.kdeplot(ax=axes[2], data=thetas, bw_method='scott', bw_adjust=0.4, c='k')\n",
    "axes[2].set_title('thetas')\n",
    "\n",
    "sns.histplot(ax=axes[3], data=norm_firings, bins=20, stat='density')\n",
    "sns.kdeplot(ax=axes[3], data=norm_firings, bw_method='scott', bw_adjust=0.4, c='k')\n",
    "axes[3].set_title('norm firing')\n",
    "\n",
    "plt.savefig(plot_specs.directory + 'scores_scales_thetas' + '_' + plot_specs.index + \".pdf\", \\\n",
    "            dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
